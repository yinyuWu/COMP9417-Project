{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different functions and implementations\n",
    "___\n",
    "1. Euclidean distance implementation\n",
    "2. Manhattan distance implementation\n",
    "3. Testing KNN classification with leave-one-out cross-validation using SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 34)\n",
      "(351,)\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "dataset = arff.loadarff('ionosphere.arff')\n",
    "dataset = pd.DataFrame(dataset[0])\n",
    "dataset = dataset.to_numpy()\n",
    "X = dataset[:, :-1].astype(np.float64) # cast datatype from 'float' to 'np.float64' (seems to be faster)\n",
    "y = dataset[:, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Euclidean distance implementation\n",
    "___\n",
    "Conclusion: euclidean6() seems to be best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.linalg.norm(): 4.424055650802779\n",
      "euclidean1: 4.424055650802779\n",
      "euclidean2: 4.424055650802779\n",
      "euclidean3: 4.424055650802779\n",
      "euclidean4: 4.424055650802779\n",
      "euclidean5: 4.424055650802779\n",
      "euclidean6: 4.424055650802779\n",
      "euclidean7: 4.424055650802779\n",
      "euclidean8: 4.424055650802779\n",
      "euclidean9: 4.424055650802779\n"
     ]
    }
   ],
   "source": [
    "# Euclidean functions\n",
    "def euclidean1(x1, x2):\n",
    "    return np.sqrt(np.sum((x2 - x1)**2))\n",
    "\n",
    "def euclidean2(x1, x2):\n",
    "    diff = x2 - x1\n",
    "    return np.sqrt(np.sum((diff)**2))\n",
    "\n",
    "def euclidean3(x1, x2):\n",
    "    return np.sqrt(np.sum(np.square(x2 - x1)))\n",
    "\n",
    "def euclidean4(x1, x2):\n",
    "    diff = x2 - x1\n",
    "    return np.sqrt(np.sum(np.square(diff)))\n",
    "\n",
    "def euclidean5(x1, x2):\n",
    "    return np.sqrt(np.dot(x2 - x1, x2 - x1))\n",
    "\n",
    "def euclidean6(x1, x2):\n",
    "    diff = x2-x1\n",
    "    return np.sqrt(np.dot(diff, diff))\n",
    "\n",
    "def euclidean7(x1, x2):\n",
    "    return np.sqrt(np.inner(x2 - x1, x2 - x1))\n",
    "\n",
    "def euclidean8(x1, x2):\n",
    "    diff = x2-x1\n",
    "    return np.sqrt(np.inner(diff, diff))\n",
    "\n",
    "def euclidean9(x1, x2):\n",
    "    diff = x2-x1\n",
    "    return np.sqrt(np.einsum('i,i->', diff, diff))\n",
    "\n",
    "# Output of functions\n",
    "m = X.shape[0] # number of examples\n",
    "x1 = X[np.random.randint(0, m)]\n",
    "x2 = X[np.random.randint(0, m)]\n",
    "print('np.linalg.norm():', np.linalg.norm(x2-x1))\n",
    "print('euclidean1:', euclidean1(x1, x2))\n",
    "print('euclidean2:', euclidean2(x1, x2))\n",
    "print('euclidean3:', euclidean3(x1, x2))\n",
    "print('euclidean4:', euclidean4(x1, x2))\n",
    "print('euclidean5:', euclidean5(x1, x2))\n",
    "print('euclidean6:', euclidean6(x1, x2))\n",
    "print('euclidean7:', euclidean7(x1, x2))\n",
    "print('euclidean8:', euclidean8(x1, x2))\n",
    "print('euclidean9:', euclidean9(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.linalg.norm(): 11.3 µs ± 439 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean1: 14.3 µs ± 349 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean2: 14 µs ± 572 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean3: 13.3 µs ± 58.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean4: 14.3 µs ± 1.05 µs per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean5: 8.97 µs ± 341 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean6: 6.77 µs ± 27.7 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean7: 8.93 µs ± 44.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean8: 6.98 µs ± 55.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "euclidean9: 8.84 µs ± 68.6 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "print('np.linalg.norm(): ', end='')\n",
    "%timeit diff = x2 - x1; np.linalg.norm(diff)\n",
    "print('euclidean1: ', end='')\n",
    "%timeit euclidean1(x2, x1)\n",
    "print('euclidean2: ', end='')\n",
    "%timeit euclidean2(x2, x1)\n",
    "print('euclidean3: ', end='')\n",
    "%timeit euclidean3(x2, x1)\n",
    "print('euclidean4: ', end='')\n",
    "%timeit euclidean4(x2, x1)\n",
    "print('euclidean5: ', end='')\n",
    "%timeit euclidean5(x2, x1)\n",
    "print('euclidean6: ', end='')\n",
    "%timeit euclidean6(x2, x1)\n",
    "print('euclidean7: ', end='')\n",
    "%timeit euclidean7(x2, x1)\n",
    "print('euclidean8: ', end='')\n",
    "%timeit euclidean8(x2, x1)\n",
    "print('euclidean9: ', end='')\n",
    "%timeit euclidean9(x2, x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Manhattan distance implementation\n",
    "___\n",
    "Conclusion: manhattan1 works fine. manhattan2 is probably calculated the exact same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.679720000000003\n",
      "21.679720000000003\n",
      "21.679720000000003\n"
     ]
    }
   ],
   "source": [
    "def manhattan1(x1, x2):\n",
    "    return np.sum(np.abs(x2 - x1))\n",
    "\n",
    "def manhattan2(x1, x2):\n",
    "    diff = x2 - x1\n",
    "    return np.sum(np.abs(diff))\n",
    "\n",
    "# Output of functions\n",
    "print(np.linalg.norm(x2 - x1, ord=1))\n",
    "print(manhattan1(x1, x2))\n",
    "print(manhattan2(x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit diff = x2 - x1; np.linalg.norm(diff, ord=1)\n",
    "%timeit manhattan1(x, X[1])\n",
    "%timeit manhattan2(X[0], X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn KNN Classifier\n",
    "___\n",
    "I think this is how they want us to calculate accuracy. Train on all except 1 example, then predict on that single test example. Repeat for all possible splits. There should be m splits where m is the number of examples in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn doesn't like y labels of type 'bytes'\n",
    "y = y.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature scaling\n",
    "def KNNclassifierWithLOO(X, y):\n",
    "    # Leave one out cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "\n",
    "    # KNN classifier\n",
    "    correct_count = 0;\n",
    "    total_count = y.shape[0];\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "    # Train on each split and predict on the single test example\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        if y_pred == y_test:\n",
    "            correct_count += 1\n",
    "\n",
    "    #print(correct_count, 'out of', total_count, 'correctly classified')\n",
    "    #print('accuracy:', correct_count / total_count)\n",
    "    return correct_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8490028490028491\n"
     ]
    }
   ],
   "source": [
    "accuracy = KNNclassifierWithLOO(X, y)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487 ms ± 45.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit KNNclassifierWithLOO(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With standard scaler\n",
    "def KNNclassifierWithLOOandStandardScaler(X, y):\n",
    "    # Leave one out cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "\n",
    "    # KNN classifier\n",
    "    correct_count = 0;\n",
    "    total_count = y.shape[0];\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Train on each split and predict on the single test example\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        if y_pred == y_test:\n",
    "            correct_count += 1\n",
    "\n",
    "    #print(correct_count, 'out of', total_count, 'correctly classified')\n",
    "    #print('accuracy:', correct_count / total_count)\n",
    "    return correct_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = KNNclassifierWithLOOandStandardScaler(X, y)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With min max scaler\n",
    "def KNNclassifierWithLOOandMinMaxScaler(X, y):\n",
    "    # Leave one out cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X)\n",
    "\n",
    "    # KNN classifier\n",
    "    correct_count = 0;\n",
    "    total_count = y.shape[0];\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Train on each split and predict on the single test example\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train = X[train_index]\n",
    "        X_test = X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        y_test = y[test_index]\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        if y_pred == y_test:\n",
    "            correct_count += 1\n",
    "\n",
    "    #print(correct_count, 'out of', total_count, 'correctly classified')\n",
    "    #print('accuracy:', correct_count / total_count)\n",
    "    return correct_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = KNNclassifierWithLOOandMinMaxScaler(X, y)\n",
    "print('accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
